<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>DS Interview Study Guide Part I: Statistics - Ramya Bygari</title>
<meta name="description" content="Part I of my guide to data science interviews, focusing on statistics and experimental design.">


  <meta name="author" content="Ramya Bygari">
  
  <meta property="article:author" content="Ramya Bygari">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Ramya Bygari">
<meta property="og:title" content="DS Interview Study Guide Part I: Statistics">
<meta property="og:url" content="http://localhost:4000/posts/2019/08/24/stats.html">


  <meta property="og:description" content="Part I of my guide to data science interviews, focusing on statistics and experimental design.">







  <meta property="article:published_time" content="2019-08-24T00:00:00+05:30">






<link rel="canonical" href="http://localhost:4000/posts/2019/08/24/stats.html">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Ramya Bygari Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Ramya Bygari
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/">Home</a>
            </li><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/portfolio/">Portfolio</a>
            </li><li class="masthead__menu-item">
              <a href="/experience/">Experience</a>
            </li><li class="masthead__menu-item">
              <a href="/assets/docs/resume.pdf">Resume</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/Ramya.png" alt="Ramya Bygari" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">Ramya Bygari</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Machine Learning and Scalable Systems</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Bangalore, India</span>
        </li>
      

      

      

      
        <li>
          <a href="mailto:ramyabygari239@gmail.com" rel="me" class="u-email">
            <meta itemprop="email" content="ramyabygari239@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      
        <li>
          <a href="https://www.linkedin.com/in/ramyabygari" itemprop="sameAs" rel="nofollow noopener noreferrer me">
            <i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span>
          </a>
        </li>
      

      

      

      

      

      
        <li>
          <a href="https://github.com/ramyabygari" itemprop="sameAs" rel="nofollow noopener noreferrer me">
            <i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="DS Interview Study Guide Part I: Statistics">
    <meta itemprop="description" content="Part I of my guide to data science interviews, focusing on statistics and experimental design.">
    <meta itemprop="datePublished" content="2019-08-24T00:00:00+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/posts/2019/08/24/stats.html" class="u-url" itemprop="url">DS Interview Study Guide Part I: Statistics
</a>
          </h1>
          


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> Contents</h4></header>
              <ul class="toc__menu"><li><a href="#the-central-limit-theorem">The Central Limit Theorem</a><ul><li><a href="#an-example">An Example</a></li><li><a href="#other-questions-on-the-clt">Other Questions on the CLT</a></li></ul></li><li><a href="#hypothesis-testing">Hypothesis Testing</a><ul><li><a href="#an-example-1">An Example</a></li><li><a href="#other-topics-in-hypothesis-testing">Other Topics in Hypothesis Testing</a></li></ul></li><li><a href="#confidence-intervals">Confidence Intervals</a><ul><li><a href="#the-exact-method">The Exact Method</a></li><li><a href="#the-approximate-method">The Approximate Method</a></li><li><a href="#the-bootstrap-method">The Bootstrap Method</a></li><li><a href="#other-topics-in-confidence-intervals">Other Topics in Confidence Intervals</a></li></ul></li><li><a href="#bootstrapping">Bootstrapping</a><ul><li><a href="#other-topics-in-bootstrapping">Other Topics in Bootstrapping</a></li></ul></li><li><a href="#linear-regression">Linear Regression</a><ul><li><a href="#calculating-a-linear-regression">Calculating a Linear Regression</a></li><li><a href="#a-statistical-view">A Statistical View</a></li><li><a href="#validating-your-model">Validating Your Model</a></li><li><a href="#basic-questions-on-lr">Basic Questions on LR</a></li><li><a href="#handling-overfitting">Handling Overfitting</a></li><li><a href="#logistic-regression">Logistic Regression</a></li></ul></li><li><a href="#bayesian-inference">Bayesian Inference</a><ul><li><a href="#bayesian-vs-frequentist-statistics">Bayesian vs Frequentist Statistics</a></li><li><a href="#basics-of-bayes-theorem">Basics of Bayes Theorem</a></li><li><a href="#updating-posteriors--conjugate-priors">Updating Posteriors &amp; Conjugate Priors</a></li></ul></li><li><a href="#maximum-likelihood-estimation">Maximum Likelihood Estimation</a></li><li><a href="#experimental-design">Experimental Design</a></li><li><a href="#conclusion">Conclusion</a></li></ul>

            </nav>
          </aside>
        
        <p>As I have gone through a couple rounds of interviews for data scientist
positions, I’ve been compiling notes on what I consider to be the essential
areas of knowledge. I want to make these notes available to the general public;
although there are many blog posts out there that are supposed to help one
prepare for data science interviews, I haven’t found any of them to be very
high-quality.</p>

<p>From my perspective, there are four key subject areas that a data scientist
should feel comfortable with when going into an interview:</p>

<ol>
  <li>Statistics (including experimental design)</li>
  <li>Machine Learning</li>
  <li>Software Engineering (including SQL)</li>
  <li>“Soft” Questions</li>
</ol>

<p>I’m going to go through each of these individually. This first post will focus
on statistics. We will go over a number of topics in statistics in no particular
order. Note that <strong>this post will not teach you statistics; it will remind you
of what you should already know.</strong></p>

<p>If you’re utterly unfamiliar with the concepts I’m mentioning, I’d recommend <a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/index.htm">this
excellent MIT course on probability &amp; statistics</a> as a good starting point. When I
began interviewing, I had never taken a statistics class before; I worked through the
notes, homeworks, and exams for this course, and at the end had a solid foundation to
learn the specific things that you need to know for these interviews. In my studying, I
also frequently use <a href="https://stats.stackexchange.com">cross-validated</a>, a website for asking and answering questions
about statistics. It’s good for in-depth discussions of subtle issues in
statistics. Finally, <a href="https://www.goodreads.com/book/show/619590.Bayesian_Data_Analysis">Gelman’s book</a> is the classic in Bayesian inference. If you
have recommendations for good books that cover frequentist statistics in a clear manner,
I’d love to hear them.</p>

<p>These are the notes that I put together in my studying, and I’m sure that there is
plenty of room for additions and corrections. I hope to improve this guide over time;
please let me know in the comments if there’s something you think should be added,
removed, or changed!</p>

<h1 id="the-central-limit-theorem">The Central Limit Theorem</h1>

<p>The Central Limit Theorem is a fundamental tool in statistical analysis. It states
(roughly) that when you add up a bunch of independent and identically distributed random
variables (with finite variance) then their sum will converge to a Gaussian
distribution.<sup id="fnref:fnote1"><a href="#fn:fnote1" class="footnote">1</a></sup></p>

<p>How is this idea useful to a data scientist? Well, one place where we see a sum of
random variables is in a <em>sample mean</em>. One consequence of the central limit theorem is
that the sample mean of a variable with mean <script type="math/tex">\mu</script> and variance <script type="math/tex">\sigma^2</script> will
itself have mean <script type="math/tex">\mu</script> and variance <script type="math/tex">\sigma^2/n</script>, where <script type="math/tex">n</script> is the number of
samples.</p>

<p>I’d like to point out that this is pretty surprising. The distribution of the sum of two
random variables is not, in general, trivial to calculate. So it’s kind of awesome that,
if we’re adding up a large enough number of (independent and identically distributed)
random variables, then we <em>do</em>, in fact, have a very easy expression for the
(approximate) distribution of the sum. Even better, we don’t need to know much of
anything about the distribution of we’re sampling from, besides its mean and
variance - it’s other moments, or general shape, don’t matter for the CLT.</p>

<p>As we will see below, the simplification that the CLT introduces is the basis of one of
the fundamental hypothesis tests that data scientists perform: testing equality of
sample means. For now, let’s work through an example of the theorem itself.</p>

<h2 id="an-example">An Example</h2>

<p>Suppose that we are sampling a Bernoulli random variable. This is a 0/1 random
variable that is 1 with probability <script type="math/tex">p</script> and 0 with probability <script type="math/tex">1-p</script>. If we
get the sequence of ten draws <script type="math/tex">[0,1,1,0,0,0,1,0,1,0]</script>, then our sample mean is</p>

<script type="math/tex; mode=display">\hat \mu = \frac{1}{10}\sum_{i=1}^{10} x_i = 0.4</script>

<p>Of course, this sample mean is itself a random variable - when we report it, we
would like to report an estimate on its variance as well. The central limit
theorem tells us that this will, as <script type="math/tex">n</script> increases, converge to a Gaussian
distribution. Since the mean of the Bernoulli random variable is <script type="math/tex">p</script> and its
variance is <script type="math/tex">p(1-p)</script>, we know that the distribution of the sample mean will
converge to a Gaussian with mean <script type="math/tex">p</script> and variance <script type="math/tex">p(1-p)/n</script>. So we could
say that our estimate of the parameter <script type="math/tex">p</script> is 0.4 <script type="math/tex">\pm</script> 0.155. Of course,
we’re playing a bit loose here, since we’re using the estimate <script type="math/tex">\hat p</script> from
the data, as we don’t actually know the <em>true</em> parameter <script type="math/tex">p</script>.</p>

<p>Now, a sample size of <script type="math/tex">n=10</script> is a bit small to be relying on a “large-<script type="math/tex">n</script>”
result like the CLT. Actually, in this case, we know the exact distribution of
the sample mean, since <script type="math/tex">\sum_i x_i</script> is binomially distributed with parameters
<script type="math/tex">p</script> and <script type="math/tex">n</script>.</p>

<h2 id="other-questions-on-the-clt">Other Questions on the CLT</h2>

<p>I find that the CLT more comes up as a piece of context in other questions
rather than as something that gets asked about directly, but you should be
prepared to answer the following questions.</p>

<ul>
  <li>
    <p><strong>What is the central limit theorem?</strong> We’ve addressed this above - I doubt
they’ll be expecting a mathematically-correct statement of the theorem, but
you should know the gist of it, along with significant limitations (finite
variance being the major one).</p>
  </li>
  <li>
    <p><strong>When can you <em>not</em> use the CLT?</strong> I think the key thing here is that you
have to be normalizing the data in an appropriate way (dividing by the sample
size), and that the underlying variance must be finite. The answer here can
get very subtle and mathematical, involving modes of convergence for random
variables and all that, but I doubt they will push you to go there, unless
you’re applying for a job specifically as a statistician.</p>
  </li>
  <li>
    <p><strong>Give me an example of the CLT in use.</strong> The classic example here is the
distribution of the sample mean converging to a normal distribution as the
number of samples grows large.</p>
  </li>
</ul>

<h1 id="hypothesis-testing">Hypothesis Testing</h1>

<p>Hypothesis testing (also known by the more verbose “null hypothesis significance
testing”) is a huge subject, both in scope and importance. We use statistics to
quantitatively answer questions based on data, and (for better or for worse) null
hypothesis significance testing is one of the primary methods by which we construct
these answers.</p>

<p>I won’t cover the background of NHST here. It’s well-covered in the MIT course; look at
<a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/">the readings</a> to find the relevant sections. Instead of covering the background,
we’ll work through one exampleof a hypothesis test. It’s simple, but it comes up all the
time in practice, so it’s essential to know. I might go so far as to say that this is
the fundamental example of hypothesis testing in data science.</p>

<h2 id="an-example-1">An Example</h2>

<p>Suppose we have two buttons, one green and one blue. We put them in front of
two different samples of users. For simplicity, let’s say that each sample has
size <script type="math/tex">n=100</script>. We observe that <script type="math/tex">k_\text{green}</script> 57 users click the green
button, and only <script type="math/tex">k_\text{blue} = 48</script> click the blue button.</p>

<p>Seems like the green button is better, right? Well, we want to be able to say
how <em>confident</em> we are of this fact. We’ll do this in the language of null
hypothesis significance testing. As you should (hopefully) know, in order to do NHST, we
need a null hypothesis and a test statistic; we need to know the test statistic’s
distribution (under the null hypothesis); and we need to know the probability of
observing a value “at least as extreme” as the observed value according to this
distribution.</p>

<p>I’m going to lay out a table of all the important factors here, and then discuss how we
use them to arrive at our <script type="math/tex">p</script>-value.</p>

<table>
  <thead>
    <tr>
      <th>Description</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Null Hypothesis</td>
      <td><script type="math/tex">% <![CDATA[
p_{blue} - p_{green} < 0 %]]></script></td>
    </tr>
    <tr>
      <td>Test Statistic</td>
      <td><script type="math/tex">\frac{k_\text{blue}}{n} - \frac{k_\text{green}}{n}</script></td>
    </tr>
    <tr>
      <td>Test Statistic’s Distribution</td>
      <td><script type="math/tex">N(0, (p_b(1-p_b) + p_g(1-p_g)) / n)</script></td>
    </tr>
    <tr>
      <td>Test Statistic’s Observed Value</td>
      <td>-0.09</td>
    </tr>
    <tr>
      <td><script type="math/tex">p</script>-value</td>
      <td>0.1003</td>
    </tr>
  </tbody>
</table>

<p>There are a few noteworthy things here. First, we really want to know whether
<script type="math/tex">p_g > p_b</script>, but that’s equivalent to <script type="math/tex">% <![CDATA[
p_b-p_g < 0 %]]></script>. Second, we assume that
<script type="math/tex">n</script> is large enough so that <script type="math/tex">k/n</script> is approximately normally distributed,
with mean <script type="math/tex">\mu = p</script> and variance <script type="math/tex">\sigma^2 = p(1-p)/n</script>. Third, since the
differences of two normals is itself a normal, the test statistic’s distribution
is (under the null hypothesis) a normal with mean zero and the variance given
(which is the sum of the two variances of <script type="math/tex">k_b/n</script> and <script type="math/tex">k_g/n</script>).</p>

<p>Finally, we don’t actually know <script type="math/tex">p_b</script> or <script type="math/tex">p_g</script>, so we can’t really compute
the <script type="math/tex">p</script>-value; what we do is we say that <script type="math/tex">k_b/n</script> is “close enough”” to
<script type="math/tex">p_b</script> and use it as an approximation. That gives us our final <script type="math/tex">p</script>-value.</p>

<p>The <script type="math/tex">p</script>-value was calculated in Python, as follows:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>
<span class="n">pb</span> <span class="o">=</span> <span class="mf">0.48</span>
<span class="n">pg</span> <span class="o">=</span> <span class="mf">0.57</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">pb</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">pb</span><span class="p">)</span> <span class="o">+</span> <span class="n">pg</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">pg</span><span class="p">))</span><span class="o">/</span><span class="n">n</span><span class="p">)</span>
<span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="o">-</span><span class="mf">0.09</span><span class="p">,</span> <span class="n">loc</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">)</span> <span class="c"># 0.10034431272089045</span></code></pre></figure>

<p>Calculating the CDF of a normal at <script type="math/tex">x=-0.09</script> tells us the probability that the test
statistic is less than or equal to <script type="math/tex">-0.09</script>, which is to say the probability that our
test statistic is at least as extreme as the observed value. This probability is
precisely our <script type="math/tex">p</script>-value.</p>

<p>So what’s the conclusion? Well, often times a significance level is set before the test
is performed; if the <script type="math/tex">p</script>-value is not below this threshold, then the null hypothesis
is not rejected. Suppose we had set a significance level of 0.05 before the test began -
then, with this data, we would not be able to reject the null hypothesis, which is that
the buttons are equally appealing to users.</p>

<p>Phew! I went through that pretty quick, but if you can’t follow the gist of what
I was doing there, I’d recommend you think through it until it is clear to
you. You will be faced with more complicated situations in practice; it’s
important that you begin by understanding the most simple situation inside out.</p>

<h2 id="other-topics-in-hypothesis-testing">Other Topics in Hypothesis Testing</h2>

<p>Some important follow-up questions you should be able to answer:</p>

<ul>
  <li>
    <p><strong>What are Type I &amp; II error? What is a situation where you would be more concerned
with Type I error? Vice versa?</strong> These are discussed <a href="https://en.wikipedia.org/wiki/Type_I_and_type_II_errors#Type_I_error">on Wikipedia</a>. Type I error
is false-positive error. You might be very concerned with Type I error if you are
interviewing job candidates; it is very costly to hire the wrong person for the job,
so you really want to avoid false positives. Type II error is false-negative error. If
you are testing for a disease that is deadly but has a simple cure, then you would
certainly NOT want to have a false negative result of the test, since that would
result in an easily-avoidable negative outcome.</p>
  </li>
  <li>
    <p><strong>What is the <em>power</em> of a test? How do you calculate it?</strong> The power of a test is the
probability that you will reject the null hypothesis, given an alternative
hypothesis. Therefore, to calculate the power, you need an alternative hypothesis; in
the example above, this would look like <script type="math/tex">p_b-p_g = -0.1</script>. Although these alternative
hypothesis are often somewhat ad-hoc, the power analysis depends critically upon
them. Google will turn up plenty of videos and tutorials on calculating the power of a
test.</p>
  </li>
  <li>
    <p><strong>What is the significance of a test?</strong> This is the same as the
<script type="math/tex">p</script>-value threshold below which we reject the null
hypothesis. (In)famously, 0.05 has become the de-facto standard throughout
many sciences for significance levels worthy of publication.</p>
  </li>
  <li>
    <p><strong>Gow would you explain a p-value to a lay person</strong>? Of course, you should
have a solid understanding of the statistical definition of the
<script type="math/tex">p</script>-value. A generally accepted answer is “a <script type="math/tex">p</script>-value quantifies the
evidence for a hypothesis - closer to zero means more evidence.” Of course,
this is wrong on a lot of levels - it’s actually quantifying evidence
<em>against</em> the null hypothesis, not <em>for</em> the alternative. For what it’s
worth, I’m not convinced there’s a great answer to that one; it’s an
inherently technical quantity that is frequently misrepresented and abused by
people trying to (falsely) simplify its meaning.</p>
  </li>
  <li>
    <p><strong>If you measure many different test statistics, and get a <script type="math/tex">p</script>-value for each (all
based on the same null hypothesis), how do you combine them to get an aggregate
<script type="math/tex">p</script>-value?</strong> This one is more of a bonus question, but it’s worth knowing. It’s
actually not obvious how do to this, and the true <script type="math/tex">p</script>-value depends on how the tests
depend on each other. However, you can get an upper-bound (worst-case estimate) on the
aggregate <script type="math/tex">p</script>-value by adding together the different <script type="math/tex">p</script>-values. The validity of
this bound results from the inclusion-exclusion principle.</p>
  </li>
</ul>

<h1 id="confidence-intervals">Confidence Intervals</h1>

<p>Confidence intervals allow us to state a statistical result as a range, rather than a
single value. If we count that 150 out of 400 people sample randomly from a city
identify themselves as male, then our best estimate of the fraction of women in the city
is 250/400, or 5/8. But we only looked at 400 people, so it’s reasonable to expect that
the true value might be a bit more or less than 5/8. Confidence intervals allow us to
quantify this width in a statistically rigorous way.</p>

<p>As per usual, we won’t actually introduce the concepts here - I’ll refer you to the
<a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/">readings from the MIT course</a> for an introduction. We’ll focus on working through
an example, and looking at some different approaches.</p>

<h2 id="the-exact-method">The Exact Method</h2>

<p>Suppose that we want to find a 95% confidence inverval on the female fraction in the
city discussed above. This corresponds to a significance level of <script type="math/tex">\alpha/2</script>. One way
to get the <strong>exact confidence inverval</strong> is to use the CDF of our test statistic, but
substitute in the observed parameter for the true parameter, and then invert it to find
where it hits <script type="math/tex">\alpha/2</script> and <script type="math/tex">1-\alpha/2</script>. That is, we need to find the value
<script type="math/tex">p_l</script> that solves the equation</p>

<script type="math/tex; mode=display">CDF\left(n, p_l\right) = \alpha/2</script>

<p>and the value <script type="math/tex">p_u</script> that solves the equation</p>

<script type="math/tex; mode=display">CDF\left(n, p_u\right) = 1 - \alpha/2.</script>

<p>In these, <script type="math/tex">CDF(n,p)</script> is the cumulative distribution function of our test statistic,
assuming that the true value of <script type="math/tex">p</script> is in fact the observed value <script type="math/tex">\hat p</script>. This is
a bit confusing, so it’s worth clarifying. In our case, the sample statistic is the
sample mean of <script type="math/tex">n</script> binomial random variables, so this CDF is the CDF of the sample
mean of <script type="math/tex">n</script> binomial random variables with parameter <script type="math/tex">5/8</script>. Solving the two
equations above would give us our confidence inverval <script type="math/tex">[p_l, p_u]</script>.</p>

<p>It took me a bit of work to see that solving the above two equations would in fact give
us bounds that satisfy the definitions of a <script type="math/tex">1-\alpha</script> confidence interval, which says
that, were we to run many experiments, we would find that the true value of <script type="math/tex">p</script> would
fall between <script type="math/tex">p_l</script> and <script type="math/tex">p_u</script> with the probability</p>

<script type="math/tex; mode=display">P\left(p_l\leq p \leq p_u\right) = 1-\alpha.</script>

<p>If you’re into this sort of thing, I’d suggest you take some time thinking through why
inverting the CDF as above guarantees bounds <script type="math/tex">[p_l, p_u]</script> that solve the above
equaiton.</p>

<p>Although it is useful for theoretical analysis, I rarely use this method in
practice, because I often do not actually know the true CDF of the statistic
I am measuring. Sometimes I do know the true CDF, but even in such cases, the
next (approximate) method is generally sufficient.</p>

<h2 id="the-approximate-method">The Approximate Method</h2>

<p>If your statistic can be phrased as a sum, then its distribution approaches a normal
distribution.<sup id="fnref:fnote2"><a href="#fn:fnote2" class="footnote">2</a></sup> This means that you can solve the above equations for a normal
CDF rather than the true CDF of the sum (in the case above, a binomial CDF).</p>

<p>How does this help? For a normal distribution, the solutions for the above equations to
find lower and upper bounds are well known. In particular, the inverval
<script type="math/tex">[\mu-\sigma,\mu+\sigma]</script>, also called a <script type="math/tex">1\sigma</script>-interval, covers about 68% of the
mass (probability) of the normal PDF, so if we wanted to find a confidence interval of
level <script type="math/tex">0.68</script>, then we know to use the bounds <script type="math/tex">(\overline x-\sigma, \overline
x+\sigma)</script>, where <script type="math/tex">\overline x</script> is our estimate of the true mean <script type="math/tex">\mu</script>.</p>

<p>This sort of result is very powerful, because it saves us from having to do any
inversion by hand. A table below indicates the probability mass contained in various
symmetric intervals on a normal distribution:</p>

<table>
  <thead>
    <tr>
      <th>Inverval</th>
      <th>Width<sup id="fnref:fnote3"><a href="#fn:fnote3" class="footnote">3</a></sup></th>
      <th>Coverage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><script type="math/tex">[\mu-\sigma,\mu+\sigma]</script></td>
      <td><script type="math/tex">1\sigma</script></td>
      <td>0.683</td>
    </tr>
    <tr>
      <td><script type="math/tex">[\mu-2\sigma,\mu+2\sigma]</script></td>
      <td><script type="math/tex">2\sigma</script></td>
      <td>0.954</td>
    </tr>
    <tr>
      <td><script type="math/tex">[\mu-3\sigma,\mu+3\sigma]</script></td>
      <td><script type="math/tex">3\sigma</script></td>
      <td>0.997</td>
    </tr>
  </tbody>
</table>

<p>Let’s think through how we would use this in the above example, where we give a
confidence interval on our estimate of the binomial parameter <script type="math/tex">p</script>.</p>

<p>A binomial distribution has mean <script type="math/tex">\mu=np</script> and variance <script type="math/tex">\sigma^2=np(1-p)</script>. Since
the sample statistical <script type="math/tex">\hat p</script> is just the binomial divided by <script type="math/tex">n</script>, it has mean
<script type="math/tex">\mu=p</script> and variance <script type="math/tex">\sigma^2 = p(1-p)/n</script>. The central limit theorem tells us that
the distribution of <script type="math/tex">\hat p</script> will converge to a normal with just these parameters.</p>

<p>Suppose we want an (approximate) 95% confidence interval on the percentage of women in
the population of our city; the table above tells us we can just do a two-sigma
interval. (This is not <em>exactly</em> a 95% confidence interval; it’s a bit over, as we see
in the table above). The parameter <script type="math/tex">\hat p</script> has mean <script type="math/tex">\mu= p</script> and variance
<script type="math/tex">\sigma^2 = p(1-p)/n</script>.<sup id="fnref:fnote4"><a href="#fn:fnote4" class="footnote">4</a></sup> In our case, <script type="math/tex">\hat p=5/8</script>, so our confidence
interval is <script type="math/tex">5/8 \pm 15/1280 \approx 0.625 \pm 0.0117</script>. Note that we approximated
<script type="math/tex">p</script> with our experimental value <script type="math/tex">\hat p</script>; the theoretical framework that allows us
to do this substitution is beyond the scope of this article, but is nicely covered in
the MIT readings (Reading 22, in particular).</p>

<h2 id="the-bootstrap-method">The Bootstrap Method</h2>

<p>The previous approach relies on the accuracy of approximating our statistic’s
distribution by a normal distribution. Bootstrapping is a pragmatic, flexible
approach to calculating confidence intervals, which makes no assumptions on the
underlying statistics we are calculating. We’ll go into more detail on
bootstrapping in general below, so we’ll be pretty brief here.</p>

<p>The basic idea is to repeatedly pull 400 samples <em>with replacement</em> from the sampled
data. For each set of 400 samples, we get an estimate <script type="math/tex">\hat p</script>, and thus can build an
empirical distribution on <script type="math/tex">\hat p</script>. Of course, the CLT indicates that this empirical
distribution should look a lot like a gaussian distribution with mean <script type="math/tex">\mu= p</script> and variance
<script type="math/tex">\sigma^2 = p(1-p)/n</script>..</p>

<p>Once you have bootstrapped an empirical distribution for your statistic of interest (in
the example above, this is the percentage of the population that is women), then you can
simply find the <script type="math/tex">\alpha/2</script> and <script type="math/tex">1-\alpha/2</script> percentiles, which then become your
confidence interval. Although in this case our empirical distribution is (approximately)
normal, it’s worth realizing that we can reasonably calculate percentiles <em>regardless</em>
of what the empirical distribution is; this is why bootstrapping confidence intervals
are so flexible.</p>

<p>As you’ll see below, the downside of bootstrapping confidence intervals is that
it requires some computation. The amount of computation required can be
anywhere from trivial to daunting, depending on how many samples you want in
your empirical distribution. Another downside is that their statistical interpretation
is not exactly in alignment with the definition of a confidence interval, but I’ll leave
the consideration of that as an exercise for the reader.<sup id="fnref:fnotez"><a href="#fn:fnotez" class="footnote">5</a></sup> <a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading24.pdf">One of the MIT
readings</a> has an in-dpeth discussion of confidence intervals generated via the
bootstrap method.</p>

<p><strong>Overall, I would recommend using the approximate method when you have good reason to
believe your sample statistic is approximately normal, or bootstrapping otherwise.</strong> Of
course, the central limit theorem can provide some guarantees about the asympototic
distribution of certain statistics, so it’s worth thinking through whether that applies
to your situations.</p>

<h2 id="other-topics-in-confidence-intervals">Other Topics in Confidence Intervals</h2>

<ul>
  <li>
    <p><strong>What is the definition of a confidence interval?</strong> This is a bit more technical, but
it’s essential to know that it is <strong>not</strong> “there is a 95% probability that the true
parameter is in this range.” Actually, what it means is that “if you reran the
experiment many times, then 95% of the time, the true value of the parameter you’re
estimating would fall in this range.” It’s worth noting that the <em>range</em> is the random
variable here - the parameter itself (the true percentage of the population that
identifies as female, in our example) is fixed.</p>
  </li>
  <li>
    <p><strong>How would this change if you wanted a <em>one-sided</em> confidence interval?</strong>
This one isn’t too bad - you just solve either <script type="math/tex">CDF(n,p_l) = \alpha</script> or
<script type="math/tex">CDF(n,p_u) = 1-\alpha</script> for a lower- or upper-bounded interval,
respectively.</p>
  </li>
  <li>
    <p><strong>What is the relationship between confidence intervals and hypothesis testing?</strong>
There are many ways to answer this question; it’s a good one to ponder in order to get
a deeper understanding of the two topics. One connection is the relationship between
confidence intervals and rejection regions in NHST - Reading 22 in the MIT course
addresses this one nicely.</p>
  </li>
</ul>

<h1 id="bootstrapping">Bootstrapping</h1>

<p>Bootstrapping is a technique that allows you to get insight into the quality of your
estimates, based only on the data you have. It’s a key tool in a data scientist’s
toolbag, because we frequently don’t have a clear theoretical understanding of our
statistics, and yet we want to provide uncertainty estimates. To understand how it
works, let’s look through an example.</p>

<p>In the last section, we sampled 400 people in an effort to understand what percentage of
a city’s population identified as female. Since 250 of them identified themselves as
female, our estimate of the raio for the total population is <script type="math/tex">5/8</script>. This estimate it
itself a random variable; if we had sampled different people, we might have ended up
with a different number. What if we want to know the distribution of this estimate? How
would we go about getting that?</p>

<p>Well, the obvious way is to go out and sample 400 more people, and repeat this over and
over again, until we have many such fractional estimates. But what if we don’t have
access to sampling more people? The natural thing is to think that we’re out of luck -
without the ability to sample further, we can’t actually understand more about the
distribution of our parameter (ignoring, for the moment, that we have lots of
theoretical knowledge about it via the CLT).</p>

<p>The idea behind bootstrapping is simple. Sample from the data you already have, with
replacement, a new sample of 400 people. This will give you an estimate of the female
fraction that is distinct from your original estimate, due to the replacement in your
sampling. You can repeat this process as many times as you like; you will then get an
empirical distribution whic approaches the true distribution of the statistic.<sup id="fnref:fnote4:1"><a href="#fn:fnote4" class="footnote">4</a></sup></p>

<p>Bootstrapping has the advantage of belig flexible, although it does have its
limitations. Rather than get too far into the weeds, I’ll just point you to the
<a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">Wikipedia article on bootstrapping</a>. There are also tons of resources about this
subject online. Try coding it up for yourself! By the time you’re interviewing, you
should be able to write a bootstrapping algorithm quite easily.</p>

<p><a href="https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/">Machine Learning Mastery</a> has a good introduction to bootstrapping that uses the
scikit-learn API. <a href="https://towardsdatascience.com/an-introduction-to-the-bootstrap-method-58bcb51b4d60">Towards Data Science</a> codes it up directly in NumPy, which is a
useful thing to know how to be able to do. Asking someone to code up a bootstrapping
function would be an entirely reasonable interview questions, so it’s something you
should be comfortable doing.</p>

<h2 id="other-topics-in-bootstrapping">Other Topics in Bootstrapping</h2>

<ul>
  <li><strong>When would you <em>not</em> want to use bootstrapping?</strong> It might not be feasible when it
is very costly to calculate your sample statistic. To get accurate estimates you’ll
need to calculate your statistic thousands of times, so it might not be feasible if it
takes minutes or hours to calculate a single sample. Also, it is often difficult to
get strong theoretical guarantees about probabilities based on bootstrapping, so if
you need a highly statistically rigorous approach, you might be better served with
something more analytical. Finally, if you know the distribution of your statistic
already (for example, you know from the CLT that it is normally distributed) then you
can get better (more accurate) uncertainty estimates from an analytical approach.</li>
</ul>

<h1 id="linear-regression">Linear Regression</h1>

<p>Regression is the study of the relationship between variables; for example, we
might wish to know how the weight of a person relates to their height. <em>Linear</em>
regression assumes that your input (height, or <script type="math/tex">h</script>) and output (weight, or
<script type="math/tex">w</script>) variables are <em>linearly related</em>, with slope <script type="math/tex">\beta_1</script>, intercept
<script type="math/tex">\beta_0</script>, and noise <script type="math/tex">\epsilon</script>.</p>

<script type="math/tex; mode=display">w = \beta_1\cdot h + \beta_0 + \epsilon.</script>

<p>A linear regression analysis helps the user discover the <script type="math/tex">\beta</script>s in the
above equation. This is just the simplest application of LR; in reality, it is
quite flexible and can be used in a number of scenarios.</p>

<p>Linear regression is another large topic that I can’t really do justice to in this
article. Instead, I’ll just go through some of the common topics, and introduce the
questions you should be able to address. As is the case with most of these topics, you
can look at the <a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/index.htm">MIT Statistics &amp; Probability course</a> for a solid academic
introduction to the subject. You can also dig through <a href="https://en.wikipedia.org/wiki/Linear_regression">the Wikipedia article</a> to get
a more in-depth picture. The subject is so huge, and there’s so much to learn about it,
that you really can spend as much time as you want digging into it - I’m just going to
gesture at some of the simpler aspects of it.</p>

<h2 id="calculating-a-linear-regression">Calculating a Linear Regression</h2>

<p>Rather than go through an example here, I’ll just refer you to the many available guides
that show you how to do this in code. Of course, you could do it in raw NumPy, solving
the normal equations explicitly, but I’d recommend using scikit-learn or statsmodels, as
they have much nicer interfaces, and give you all sorts of additional information about
your model (<script type="math/tex">r^2</script>, <script type="math/tex">p</script>-value, etc.)</p>

<p><a href="https://realpython.com/linear-regression-in-python/">Real Python</a> has a good guide to coding this up - see the section “Simple Linear
Regression with scikit-learn.” <a href="https://www.geeksforgeeks.org/linear-regression-python-implementation/">GeeksForGeeks</a> does the solution in raw NumPy; the
equations won’t be meaningful for you until you read up on the normal equation and how
to analytically solve for the optimal LR coefficients. If you want something similar in
R, or Julia, or MATLAB,<sup id="fnref:fnoted"><a href="#fn:fnoted" class="footnote">6</a></sup> then I’m sure it’s out there, you’ll just have to go do
some Googling to find it.</p>

<h2 id="a-statistical-view">A Statistical View</h2>

<p>This subject straddles the boundary between statistics and machine-learning. It has been
quite thoroughly studied from a statistical point of view, and there are some iportant
results that you should be familiar with when thinking about linear regression from a
statistical frame.<sup id="fnref:fnotec"><a href="#fn:fnotec" class="footnote">7</a></sup></p>

<p>Let’s look back at our foundational model for linear regression. LR assumes
that your input <script type="math/tex">x</script> and output <script type="math/tex">y</script> are related via</p>

<script type="math/tex; mode=display">y_i = \beta_1\cdot x_i + \beta_0 + \epsilon_i,</script>

<p>where <script type="math/tex">\epsilon_i</script> are i.i.d., distributed as <script type="math/tex">N(0, \sigma^2)</script>. Since the
<script type="math/tex">\epsilon</script> are random variables, the <script type="math/tex">\beta_j</script> are themselves random
variables. One important question is whether there is, in fact, any
relationship between our variables at all. If there is not, then we should
<script type="math/tex">\beta_1</script> close to 0,<sup id="fnref:fnoteb"><a href="#fn:fnoteb" class="footnote">8</a></sup> but they will not ever be exactly zero. One important
statistical technique in LR is <strong>doing a hypothesis test against the null
hypothesis that <script type="math/tex">\beta_1 = 0</script></strong>. When a package like scikit-learn returns a
“<script type="math/tex">p</script>-value of the regression”, this is the <script type="math/tex">p</script>-value they are talking
about.</p>

<p>Like I said before, there is a lot more to know about the statistics of linear
regression than just what I’ve said here. You can learn more about the statistics of LR
by looking at the <a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading25.pdf">MIT course notes on the subject</a>, or by digging through your
favorite undergraduate statistics book - most of them should have sections covering it.</p>

<h2 id="validating-your-model">Validating Your Model</h2>

<p>Once you’ve calculated your LR, you’d like to validate it. This is very important to
do - if you’re asked to calculate a linear regression in an interview, you should always
go through the process of validating it after you’ve done the calculation.</p>

<p>I’d generally go through the following steps:</p>

<ul>
  <li>If it’s just a simple (one independent variable) linear regression, then plot the two
variables. This should give you a good sense of whether it’s a good idea to use linear
regression in the first place. If you have multiple independent variables, you can
make separate plots for each one.</li>
  <li>Look at your <script type="math/tex">r^2</script> value. Is it reasonably large? Remember, closer to 1 is
better. If it’s small, then doing a linear regression hasn’t helped much.</li>
  <li>You can look at the <script type="math/tex">p</script>-value to see if it’s difference from zero is
statistically significant (see the section below). Also, you can have a very
significant <script type="math/tex">p</script>-value while still having a low <script type="math/tex">r^2</script>, so be cautious in your
interpretation of this one.</li>
  <li>You can also look at the RMSE of your model, but this number is not scaled between 0
and 1, so a “good” RMSE is highly dependent on the units of your indepedent variable.</li>
  <li>Plot your residuals, for each variable. The residual is just the input minus
the value predicted by your model, a.k.a. the error of your model. Plotting
each residual isn’t really feasible if you have hundreds of independent
variables, but it’s a good idea if your data is small enough. You should be
looking for “homoskedasticity” - that the variance of the error is uniform
across the range of the independent variable. If it’s not, then certain
things you’ve calculated (for example, the <script type="math/tex">p</script>-value of your regression)
are no longer valid. You might also see that your errors have a bias that
changes as the <script type="math/tex">x_i</script> changes; this means that there’s some more complicated
relationship between <script type="math/tex">y</script> and <script type="math/tex">x_i</script> that your regression did not pick up.</li>
</ul>

<p>Some of the questions below address the assumptions of linear regression; you
should be familiar with them, and now how to test for them either before or
after the regression is performed, so that you can be confident that your model
is valid.</p>

<h2 id="basic-questions-on-lr">Basic Questions on LR</h2>

<p>Hopefully you’ve familiarized yourself with the basic ideas behind linear
regression. Here are some conceptual questions you should be able to answer.</p>

<ul>
  <li>
    <p><strong>How are the <script type="math/tex">\beta</script>s calculated?</strong> Practically, you let the library
you’re using take care of this. But behind the scenes, generally it’s solving
the so-called “normal equations”, which give you the optimal (highest
<script type="math/tex">r^2</script>) parameters possible.  You can use gradient descent to approximate
the optimal solution when the design matrix is too large to invert; this is
available via the <code class="highlighter-rouge">SGDRegressor</code> model in scikit-learn.</p>
  </li>
  <li>
    <p><strong>How do you decide if you should use linear regression?</strong> The best case is
when the data is 2- or 3-dimensional; then you can just plot the data and see
if it looks like “linear plus noise”. However, if you have lots of
independent variables, this isn’t really an option. In such a case, you
should look perform a linear regression analysis, and then look at the errors
to verify that they look normally distributed and homoskedastic (constant
variance).</p>
  </li>
  <li>
    <p><strong>What does the <script type="math/tex">r^2</script> value of a regression indicate?</strong> The <script type="math/tex">r^2</script> value
indicates “how much of the variance of the output data is explained by the
regression.” That is, your output data <script type="math/tex">y</script> has some (sample) variance, just
on its own. Once you discover the linear relationship and subtract it off,
then the remaining error <script type="math/tex">y - \beta_0 - \beta_1x</script> still has some variance,
but hopefully it’s lower - <script type="math/tex">r^2</script> is one minus the ratio of the original to
the remaining variance. When <script type="math/tex">r^2=1</script>, then your line is a perfect fit of
the data, and there is no remaining error. It is often used to explain the
“quality” of your fit, although this can be a bit treacherous - see
<a href="https://en.wikipedia.org/wiki/Anscombe%27s_quartet">Anscombe’s Quartet</a> for examples of very different situations with the
same <script type="math/tex">r^2</script> value.</p>
  </li>
  <li>
    <p><strong>What are the assumptions you make when doing a linear regression?</strong> The
Wikipedia article <a href="https://en.wikipedia.org/wiki/Linear_regression#Assumptions">addresses this point</a> quite thoroughly. This is worth
knowing, because you don’t just want to jump in and blindly do LR; you want
to be sure it’s actually a reasonable approach.</p>
  </li>
  <li>
    <p><strong>When is it a bad idea to do LR?</strong> When you do linear regression, you’re assuming a
certain relationship between your variables. Just the parameters and output of your
regression won’t tell you whether the data really are appropriate for a linear
model. <a href="https://en.wikipedia.org/wiki/Anscombe%27s_quartet">Anscombe’s Quartet</a> is a particularly striking example of how the output of
a linear regression analysis can look similar but in fact the quality of the analysis
can be radically different. Beyond this, it is a bad idea to do LR whenever the
assumptions of LR are violated by the data; see the above bullet for more info there.</p>
  </li>
  <li>
    <p><strong>Can you do linear regression on a nonlinear relationship?</strong> In many cases,
yes. What we need is for the model to be linear in the parameters <script type="math/tex">\beta</script>;
if, for example, you are comparing distance and time for a constantly
accelerating object <script type="math/tex">d = 1/2at^2</script>, and you want to do regression to
discover the acceleration <script type="math/tex">a</script>, then you can just use <script type="math/tex">t^2</script> as your
independent variable. The model relating <script type="math/tex">d</script> and <script type="math/tex">t^2</script> is linear in the
acceleration <script type="math/tex">a</script>, as required.</p>
  </li>
  <li>
    <p><strong>What does the “linear” in linear regression refer to?</strong> This one might seem
trivial, but it’s a bit of a trick question; the relationship <script type="math/tex">y =
2\log(x)</script> might not appear linear, but in fact it can be obtained via a
linear regression, by using <script type="math/tex">\log(x)</script> as the input variables, rather than
<script type="math/tex">x</script>. Of course, for this to work, you need to know ahead of time that you
want to compare against <script type="math/tex">\log(x)</script>, but this can be discovered via
trial-and-error, to some extent. So the “linear” <em>does</em>, as you’d expect,
mean that the relationship between independent and dependent variable is
linear, but you can always <em>change</em> either of them and re-calculate your
regression.</p>
  </li>
</ul>

<h2 id="handling-overfitting">Handling Overfitting</h2>

<p>Overfitting is a very important to understand, and is a fundamental challenge in machine
learning and modeling. I’m not going to go into great detail on it here; more
information will be presented in the machine learning section of the guide. There are
some techniques for handling it that are particular to LR, which is what I’ll talk about
here.</p>

<p><a href="https://realpython.com/linear-regression-in-python/">RealPython</a> has good images showing examples of over-fitting. You can
handle it by building into your model a “penalty” on the <script type="math/tex">\beta_i</script>s; that is,
tell your model “I want low error, <strong>and</strong> I don’t want large coefficients.**
The balance of these preferences is determined by a parameter, often denoted by
<script type="math/tex">\lambda</script>.</p>

<p>Since you have many <script type="math/tex">\beta</script>s, in general, you have to combine them in some
fashion. Two such ways to calculate the measure of “overall badness” (which I’ll call
<script type="math/tex">OB</script>) are</p>

<script type="math/tex; mode=display">OB = \sqrt{ \beta_1^2 + \beta_2^2 + \ldots + \beta_n^2 }</script>

<p>or</p>

<script type="math/tex; mode=display">OB = |\beta_1| + |\beta_2| + \ldots + |\beta_n|.</script>

<p>The first will tend to be emphasize outliers; that is, it is more sensitive to
single large <script type="math/tex">\beta</script>s. The second considers all the <script type="math/tex">\beta</script>s more
uniformly. If you use the first, it is called “ridge regression”, and if you
use the second it is called “LASSO regression.”</p>

<p>In mathematics, these denote the <script type="math/tex">\ell_1</script> and <script type="math/tex">\ell_2</script> norms of the vectors
of <script type="math/tex">\beta</script>s; you can in theory use <script type="math/tex">\ell_p</script> norms for any <script type="math/tex">p</script>, even
<script type="math/tex">p=0</script> (count the number of non-zero <script type="math/tex">\beta</script>s to get the overall badness) or
<script type="math/tex">p=\infty</script> (take the largest <script type="math/tex">\beta</script> as the overall badness). However, in
practice, LASSO and ridge regression are already implemented in common
packages, so it’s easy to use them right out of the box.</p>

<p>As usual, there is a LOT to learn about how LASSO and ridge regression change your
output, and what kinds of problems they can address (and/or create). I’d highly
recommend searching around the internet to learn more about them if you aren’t already
confident in your understanding of how they work.</p>

<h2 id="logistic-regression">Logistic Regression</h2>

<p>Logistic regression is a way of modifying linear regression models to get a
classification model. The statistics of logistic regression are, generally speaking, not
as clean as those of linear regression. It will be covered in the machine learning
section, so we won’t discuss it here.</p>

<h1 id="bayesian-inference">Bayesian Inference</h1>

<p>Up until now this guide has primarily focused on frequentist topics in
statistics, such as hypothesis testing and the frequentist approach to
confidence intervals. There is an entire world of Bayesian statistical
inference, which differs significantly from the frequentist approach in both
philosophy and technique. I will only touch on the most basic application of
Bayesian reasoning in this guide.</p>

<p>In this section, I will mostly defer to outside sources, who I think speak more
eloquently on the topic than I can. Some companies (such as Google, or so I’m told) tend
to focus on advanced Bayesian skills in their data science interviews; if you want to
really learn the Bayesian approach, I’d reccomend <a href="https://www.goodreads.com/book/show/619590.Bayesian_Data_Analysis">Gelman’s book</a>, which is a
classic in the field.</p>

<h2 id="bayesian-vs-frequentist-statistics">Bayesian vs Frequentist Statistics</h2>

<p>It’s worth being able to clearly discuss the difference in philosophy and approach
between the two schools of statistics. I particularly like the discussion in the MIT
course notes. They state, more or less, that while the Bayesians like to reason from
Bayes theorem</p>

<script type="math/tex; mode=display">P(H|D) = \frac{ P(D|H)P(H)}{P(D)},</script>

<p>the frequentist school thinks that “the probability of the hypothesis” is a nonsense
concept - it is not a well-founded probablistic value, in the sense that there is no
repeatable experiment you can run in which to gather relative frequency counts and
calculate probabilities. Therefore, the frequentists must reason directly from
<script type="math/tex">P(D|H)</script>, the probability of the data given the hypothesis, which is just the
<script type="math/tex">p</script>-value. The upside of this is that the probabilistic interpretation of <script type="math/tex">P(D|H)</script>
is clean and unambiguous; the downside is that it is easy to misunderstand, since what
we really think we want is “the probability that the hypothesis is true.”</p>

<p>If you want to know more about this, there are endless discussions of it all over the
internet. Like many such dichotomies (emacs vs. vim, overhand vs underhand toilet paper,
etc.) it is generally overblown - a working statistician should be familiar with, and
comfortable using, both frequentist <em>and</em> Bayesian techniques in their analysis.</p>

<h2 id="basics-of-bayes-theorem">Basics of Bayes Theorem</h2>

<p>Bayes theorem tells us how to update our belief in light of new evidence. You
should be comfortably applying Bayes theorem in order to answer basic
probability questions. The classic example is the “base rate fallacy”:</p>

<p>Consider a routine screening test for a disease. Suppose the frequency of the
disease in the population (base rate) is 0.5%. The test is highly accurate with
a 5% false positive rate and a 10% false negative rate. You take the test and
it comes back positive. What is the probability that you have the disease?</p>

<p>The answer is NOT 0.95, even though the test has a 5% false positive rate. You should be
able to clearly work through this problem, building probability tables and using Bayes
theorem to calculate the final answer. The problem is worked through in the <a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading3.pdf">MIT stats
course readings</a> (see Example 10), so I’ll defer to them for the details.</p>

<h2 id="updating-posteriors--conjugate-priors">Updating Posteriors &amp; Conjugate Priors</h2>

<p>The above approach of calculating out all the probabilites by hand works reasonbly well
when there are only a few possible outcomes in the probability space, but it doesn’t
scale well to large (discrete) probability spaces, and won’t work at all in continuous
probability spaces. In such situations, you’re still fundamentally relying on Bayes
theorem, but the way it is applied looks quite different - you end up using sums and
integrals to calculate the relevant terms.</p>

<p>Again, I’ll defer to the <a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/">MIT stats course readings</a> for the details - readings 12
and 13 are the relevant ones here.</p>

<p>It’s particularly useful to be familiar with the concept of <strong>conjugate
priors</strong>. In general, updating your priors involves computing an integral,
which as anyone who has taken calculus knows can be a pain in the ass. When
sampling from a distribution and estimating the parameters, there are certain
priors for which the updates based on successive samples work out to be very
simple.</p>

<p>For an example of this, suppose you’re flipping a biased coin and trying to
figure out the bias. This is equivalent to sampling a binomial distribution and
trying to estimate the parameter <script type="math/tex">p</script>. If your prior is uniform (flat across
the interval <script type="math/tex">[0,1]</script>), then after <script type="math/tex">N</script> flips, <script type="math/tex">k</script> of which come up heads,
your posterior probability density on <script type="math/tex">p</script> will be</p>

<script type="math/tex; mode=display">f(p) \propto p^{k}((1-p)^{N-k}.</script>

<p>This is called a <strong><script type="math/tex">\beta</script> distribution</strong>. It is kind of magical that we can
calculate this without having to do any integrals - this is because the
<script type="math/tex">\beta</script> distribution is “conjugate to” the binomial distribution. It’s
important that we started out with a uniform distribution as our prior - if we
had chosen an arbitrary prior, the algebra might not have worked out as
nicely. In particular, if we start with a non-<script type="math/tex">\beta</script> prior, then this trick
won’t work, because our prior will not be conjuage to the binomial distribution.</p>

<p>The other important conjugate pair to know is that of the Gaussian
distribution; it is, in fact, conjuage to itself, so if you estimate the
parameters of a normal distribution, those estimates are themselves normal, and
updating your belief about the parameters based on new draws from the normal
distribution is as simple as doing some algebra.</p>

<p>There are many good resources available online and in textbooks discussing
conjuage priors; <a href="https://en.wikipedia.org/wiki/Conjugate_prior">Wikipedia</a> is a good place to start.</p>

<h1 id="maximum-likelihood-estimation">Maximum Likelihood Estimation</h1>

<p>We discussed before the case where you have a bunch of survey data, and want to estimate
the proportion of the population that identifies as female. Statistically speaking,
this proportion is a <em>parameter</em> of the probability distribution over gender identity in
the that geographical region. We’ve intuitively been saying that if we see 250 out of
400 respond that they are female, then our best estimate of the proportion is 5/8. Let’s
get a little more formal about why exactly this is our best estimate.</p>

<p>First of all, I’m going to consider a simplified world in which there are only two
genders, male and female. I do this to simplify the statistics, not because it is an
accurate model of the world. In this world, if the <em>true</em> fraction of the population
that identifies as female is 0.6, then there is some non-zero probability that you would
draw a sample of 400 people in which 250 identify as female. We call this the
<em>likelihood</em> of the parameter 0.6. In particular, the binomial distribution tells us
that</p>

<script type="math/tex; mode=display">\mathcal{L}(0.6|n_\text{female}=250) =  {400 \choose 250} \,0.6^{250}\, (1-0.6)^{400-250}</script>

<p>Of course, I could calculate this for any parameter in <script type="math/tex">[0,1]</script>; if I were very far
from 5/8, however, then this likelihood would be very small.</p>

<p>Now, a natural question to ask is “which parameter <script type="math/tex">p</script> would give us the highest
likelihood?” That is, which parameter best fits our data? That is the
<strong>maximum-likelihood estimate</strong> of the parameter <script type="math/tex">p</script>. The actual calculation of that
maximum involves some calculus and a neat trick involving logarithms, but I’ll refer the
reader <a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading10b.pdf">elsewhere</a> for those details. It’s worth noting that the MLE is often our
intuitive “best guess” at the parameter; in this case, as you might anticipate,
<script type="math/tex">p=5/8</script> maximizes the likelihood of seeing 250 people out of 400 identify as female.</p>

<p>I won’t give any question here, because I honestly have not seen any in my searching
around. Even so, I think it’s an important concept to be familiar with. Maximum
likelihood estimation often provides a theoretical foundation for our intuitive
estimates of parameters, and it’s helpful to be able to justify yourself in this
framework.</p>

<p>For example, if you’re looking at samples from an exponential distribution, and you want
to identify the parameter <script type="math/tex">\lambda</script>, you might guess that since the mean of an
exponential random variable is <script type="math/tex">\mu= 1/\lambda</script>, a good guess would be <script type="math/tex">\lambda
\approx 1/\overline x</script>, where <script type="math/tex">\overline x</script> is your sample mean. In fact you would be
correct, and this is the MLE for <script type="math/tex">\lambda</script>; you should be familiar with this way of
thinking about parameter estimation.</p>

<h1 id="experimental-design">Experimental Design</h1>

<p>Last, but certainly not least, is the large subject of experimental design. This is a
more nebulous topic, and therefore harder to familiarize yourself with quickly, than the
others we’ve discussed so far.</p>

<p>If we have some new feature, we might have reason to think it will be good to include in
our product. For example, Facebook rolled out a “stories” feature some time ago (I
honestly couldn’t tell you what it does, but it’s some thing that sits on the top of
your newsfeed). However, before they expose this to all their users, they want to put it
out there “in the wild” and see how it performs. So, they run an experiment.</p>

<p>Designing this experiment in a valid way is essential to getting meaningful, informative
results. An interview question at Facebook might be: <strong>How will you analyze if launching
stories is a good idea? What data would you look at?</strong> The discussion of this question
could easily fill a full 45-minute interview session, as there are many nuances and
details to examine.</p>

<p>One basic approach would be to randomly show the “stories” feature to some people, and
not to others, and then see how it affects their behavior. This is an A/B test. Some
questions you should be thinking about are:</p>

<ul>
  <li><strong>What metrics will we want to track in order ot measure the effect of stories?</strong> For
example, we might measure the time spent on the site, the number of clicks, etc.</li>
  <li><strong>How should we randomize the two groups?</strong> Should we randomly choose every time someone
visits the site whether to show them stories or not? Or should we make a choice for
each <em>user</em> and fix that choice? Generally, user-based randomization is preferable,
although sometimes it’s hard to do across devices (think about why this is).</li>
  <li><strong>How long should we run the tests? How many people should be in each group?</strong> This
decision is often based on a <em>power calculation</em>, which gives us the probability of
rejecting the null hypothesis, given some alternative hypothesis. I personally am not
a huge fan of these because the alternative hypothesis is usually quite ad-hoc, but it
is the standard, so it’s good to know how to do it. For example, you might demand that
your test be large enough that if including stories increases site visit time by at
least one minute, our A/B test will detect that with 90% probability.</li>
  <li><strong>When can we stop the test?</strong> The important thing to note here is that you <strong>cannot</strong>
just stop the test once the results look good - you have to decide beforehand how long
you want it to run.</li>
  <li><strong>How will you deal with confounding variables?</strong> What if, due to some techincal
difficulty, you end up mostly showing stories to users at a certain time of day, or in
a certain geographical region? There are a variety of approaches here, and I won’t get
into the details, but it’s essential that you be able to answer this concern clearly
and thoroughly.</li>
</ul>

<p>It’s also worth considering scenarios where you have to analyze data after the fact in
order to perform “experiments”; sometimes you want to know (for example) if the color of
a product has affected how well it sold, and you want to do so using existing sales
data. What limitations might this impose? A key limitation is that of confounding
variables - perhaps the product in red mostly sold in certain geographic regions,
whereas the blue version sold better in other geographic regions. What impact will this
have on your analysis?</p>

<p>There are many other considerations to think about around experimental design. I don’t
have any particular posts that I like; I’d recommend searching around Google to find
more information on the topic.</p>

<p>If you have any friends that do statistics professionally, I’d suggest sketching our a
design for the above experiment and talking through it with them - the ability to think
through an experimental design is something that is best developed over years of
professional experience.</p>

<h1 id="conclusion">Conclusion</h1>

<p>This guide has focused on some of the basic aspects of statistics that get covered in
data science interviews. It is far from exhaustive - different companies focus on
different skills, and will therefore be asking you about different statistical concepts
and techniques. I haven’t discussed time-dependent statistics at all - Markov chains,
time-series analysis, forecasting, and stochastic processes all might be of interest to
employers if they are relevant to the field of work.</p>

<p>Please let me know if you have any corrections to what I’ve said here. I’m far
from a statistician, so I’m sure that I’ve made lots of small (and some large)
mistakes!</p>

<p>Stay tuned for the rest of the study guide, which should be appearing in the
coming months. And finally, best of luck with your job search! It can be a
challenging, and even demoralizing experience; just keep learning, and don’t
let rejection get you down. Happy hunting!</p>

<!-------------------------------- FOOTER ---------------------------->

<div class="footnotes">
  <ol>
    <li id="fn:fnote1">
      <p>Of course, the actual statement is careful about the mode of
convergence, and the fact that it is actually an appropriately-normalized
version of the distribution that converges, and so on. <a href="#fnref:fnote1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:fnote2">
      <p>Again, we’re being loose here - it has to have finite variance, and
the convergence is only in a specific sense. <a href="#fnref:fnote2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:fnote3">
      <p>I’m being a little loose with definitions here - the width of a
<script type="math/tex">2\sigma</script> inverval is actually <script type="math/tex">4\sigma</script>, but I think most would still
describe it using the phrase “two-sigma”. <a href="#fnref:fnote3" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:fnote4">
      <p>As usual, we’re being a bit sloppy - we’re just using the sample variance in
place of the true variance and pretending this is correct. This will work if the
number of samples <script type="math/tex">n</script> is large. If you need confidence intervals with few (say,
less than 15) samples, I recommend you look into confidence intervals based on the
student-t distribution. <a href="#fnref:fnote4" class="reversefootnote">&#8617;</a> <a href="#fnref:fnote4:1" class="reversefootnote">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:fnotez">
      <p>In doing bootstrapping, we’re really trying to find the distribution of our
statistic <script type="math/tex">\hat S</script>. So, what we find via this method are bounds <script type="math/tex">(l,u)</script> such that
<script type="math/tex">P(l\leq \hat S \leq u)\geq C</script>. How does this relate to the definition of a
confidence interval? This is a somewhat theoretic exercise, but can be helpful in
clarifying your understanding of the more technical aspects of confidence interval
computation. <a href="#fnref:fnotez" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:fnoted">
      <p>Why are you using MATLAB? Stop that. You’re not in school anymore. <a href="#fnref:fnoted" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:fnotec">
      <p>Some of the issues that arise here (for example, over- and
under-fitting) have solutions that are more practical and less theoretical and
statistical in nature - these will be covered in more depth in the machine
learning portion of this guide, and so we don’t go into too much detail in this
section. <a href="#fnref:fnotec" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:fnoteb">
      <p><script type="math/tex">\beta_0</script> just represents the difference in the mean of the two
variables, so it could be non-zero even if the two are independent. <a href="#fnref:fnoteb" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

        
      </section>

      <footer class="page__meta">
        
        


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2019-08-24T00:00:00+05:30">August 24, 2019</time></p>

      </footer>

      

      
  <nav class="pagination">
    
      <a href="/posts/2019/07/05/metrics-paper.html" class="pagination--pager" title="New Paper: Metrics For Graph Comparison
">Previous</a>
    
    
      <a href="/posts/2019/08/29/engineering.html" class="pagination--pager" title="DS Interview Study Guide Part II: Software Engineering
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 Ramya Bygari. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="http://localhost:4000/assets/js/main.min.js"></script>








<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<script src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>




  </body>
</html>
